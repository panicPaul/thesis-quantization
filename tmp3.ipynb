{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management.data_classes import UnbatchedFlameParams\n",
    "from jaxtyping import Float\n",
    "\n",
    "\n",
    "def flame_params_to_code(params: UnbatchedFlameParams) -> Float[torch.Tensor, 'batch time 103']:\n",
    "    expr = params.expr\n",
    "    jaw = params.jaw\n",
    "    return torch.cat([expr, jaw], dim=-1).unsqueeze(0)\n",
    "\n",
    "\n",
    "a = sm.flame_params[:]\n",
    "code = flame_params_to_code(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SequenceManager\n",
    "\n",
    "sm = SequenceManager(3)\n",
    "sm.cameras[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.video_utils import side_by_side\n",
    "\n",
    "seq = 8\n",
    "side_by_side(\n",
    "    # f'tmp/pred/2dgs_full_res_500k_overnight_rigging_large_lpips/flame/sequence_{seq}.mp4',\n",
    "    f'tmp/gt/masked/sequence_{seq}.mp4',\n",
    "    f'tmp/pred/2dgs_full_res_500k_overnight_rigging_large_lpips/audio/sequence_{seq}.mp4',\n",
    "    f'tmp/pred/2dgs_full_res_500k_overnight_rigging_large_lpips/side_by_side/sequence_{seq}.mp4',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.dataset_statistics import plot_dataset_stats\n",
    "\n",
    "fig = plot_dataset_stats()\n",
    "fig.write_image(\"figures/dataset_statistics.pdf\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'a85'\n",
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import evaluate\n",
    "\n",
    "gt_dir = 'tmp/gt/masked'\n",
    "pred_dir = 'tmp/pred/2dgs_full_res_500k_overnight_rigging_large_lpips/audio'\n",
    "\n",
    "evaluate(gt_dir, pred_dir, device='cuda', sequences=[i for i in range(80, 82)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import evaluate\n",
    "\n",
    "gt_dir = 'tmp/gt/masked/other_guy'\n",
    "pred_dir = 'tmp/pred/other_guy/flame'\n",
    "\n",
    "evaluate(gt_dir, pred_dir, device='cuda', sequences=[9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import plot_all_visualizations\n",
    "\n",
    "for key, value in plot_all_visualizations(pred_dir).items():\n",
    "    print(key)\n",
    "    value.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SequenceManager\n",
    "from thesis.constants import TEST_CAMS, OTHER_GUY_DATA_DIR\n",
    "\n",
    "# i = np.random.randint(1, 10)\n",
    "sm = SequenceManager(5, data_dir=OTHER_GUY_DATA_DIR, cameras=TEST_CAMS)\n",
    "# j = np.random.randint(0, len(sm))\n",
    "img = sm.images[66][0].numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.flame_params[66:67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.constants import TEST_CAMS\n",
    "from thesis.data_management import SequenceManager\n",
    "\n",
    "j = np.random.randint(80, 101)\n",
    "sm = SequenceManager(j, cameras=TEST_CAMS)\n",
    "i = np.random.randint(0, len(sm))\n",
    "img = sm.images[i][0]\n",
    "cut_pixels = 350\n",
    "img = img[:-cut_pixels].numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.video_utils import load_video, get_audio_path\n",
    "from thesis.data_management import SequenceManager\n",
    "\n",
    "# window = 21\n",
    "# 80,81,85\n",
    "# 80: 114, 94, 93\n",
    "# 81: 126, 106, 105\n",
    "# 85: 136, 117, 115 (???)\n",
    "# 92: 96, 76, 75\n",
    "# 93: 124, 105, 103 (???)\n",
    "# 95: 126, 106, 105\n",
    "# 97: 117, 97, 96\n",
    "# 100: 150, 130, 129\n",
    "\n",
    "sequence = 85\n",
    "audio_path = get_audio_path(sequence)\n",
    "gt_path = f'tmp/gt/masked/sequence_{sequence}.mp4'\n",
    "gt_video = load_video(gt_path)\n",
    "gt_video = torch.from_numpy(gt_video)\n",
    "\n",
    "pred_path = f'tmp/pred/2dgs_full_res_500k_overnight_rigging_large_lpips/flame/sequence_{sequence}.mp4'\n",
    "pred_video = load_video(pred_path)\n",
    "pred_video = torch.from_numpy(pred_video)\n",
    "\n",
    "print(gt_video.shape, pred_video.shape)\n",
    "\n",
    "sm = SequenceManager(sequence)\n",
    "sm.audio_features[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 100\n",
    "window_size = 21\n",
    "l = range(window_size // 2, n_frames - window_size//2)\n",
    "len(list(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.video_utils import get_audio_path\n",
    "import soundfile as sf\n",
    "\n",
    "audio_path = get_audio_path(sequence)\n",
    "audio, sr = sf.read(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.audio_features[:].shape[0] / (audio.shape[0] / sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import evaluate\n",
    "\n",
    "gt_dir = 'tmp/gt/masked'\n",
    "pred_dir = 'tmp/pred/2dgs_full_res_500k_overnight_rigging_large_lpips/flame'\n",
    "\n",
    "evaluate(gt_dir, pred_dir, device='cuda', sequences=[i for i in range(80, 102)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import plot_all_visualizations\n",
    "\n",
    "for key, value in plot_all_visualizations(pred_dir).items():\n",
    "    print(key)\n",
    "    value.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import _EvaluationComputer\n",
    "\n",
    "ec = _EvaluationComputer()\n",
    "ec.cuda()\n",
    "ec.forward(gt_video, pred_video, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import fov_video_vdp\n",
    "\n",
    "score, heatmap = fov_video_vdp(gt_video=gt_video, pred_video=pred_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.video_utils import save_video\n",
    "\n",
    "save_video(heatmap, 'tmp/heatmap.mp4', audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.video_utils import side_by_side\n",
    "import os\n",
    "\n",
    "sequence = 100\n",
    "name = '2dgs_full_res_500k_noisy_audio/flame'\n",
    "gt_path = f'tmp/gt/sequence_{sequence}.mp4'\n",
    "pred_path = f'tmp/pred/{name}/sequence_{sequence}.mp4'\n",
    "output_dir = f'tmp/side_by_side/{name}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = f'{output_dir}/sequence_{sequence}.mp4'\n",
    "side_by_side(gt_path, pred_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.flame import FlameHeadWithInnerMouth\n",
    "from thesis.data_management import SequenceManager, UnbatchedFlameParams\n",
    "\n",
    "t = 218\n",
    "\n",
    "sm = SequenceManager(3)\n",
    "flame_head = FlameHeadWithInnerMouth()\n",
    "flame_head = flame_head.cuda()\n",
    "# vertices = torch.load('tmp.pt', weights_only=True)\n",
    "flame_params = sm.flame_params[t:t + 1]\n",
    "flame_params = UnbatchedFlameParams(\n",
    "    shape=flame_params.shape.cuda(),\n",
    "    expr=flame_params.expr.cuda(),\n",
    "    neck=flame_params.neck.cuda(),\n",
    "    #neck=torch.ones_like(flame_params.neck).cuda() * 0.5,\n",
    "    jaw=flame_params.jaw.cuda(),\n",
    "    eye=flame_params.eye.cuda(),\n",
    "    scale=flame_params.scale.cuda(),\n",
    ")\n",
    "flame_vertices = flame_head(flame_params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flame_vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.gaussian_splatting.rigged_gaussian_splatting import RiggedGaussianSplatting\n",
    "\n",
    "checkpoint_path = 'tb_logs/rigid_gs/static/static_initialization/version_3/checkpoints/epoch=29-step=135000.ckpt'\n",
    "\n",
    "model = RiggedGaussianSplatting.load_from_checkpoint(checkpoint_path, ckpt_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SingleSequenceDataset\n",
    "from thesis.constants import TRAIN_CAMS\n",
    "\n",
    "time_step = 218\n",
    "sequence = 3\n",
    "\n",
    "train_set = SingleSequenceDataset(\n",
    "    cameras=TRAIN_CAMS,\n",
    "    sequence=sequence,\n",
    "    start_idx=time_step,\n",
    "    end_idx=time_step + 1,\n",
    "    n_cameras_per_frame=1,\n",
    "    length_multiplier=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_set[0].image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.deformation_field.rigging_params import RiggingParams\n",
    "\n",
    "model = RiggingParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_idx = flame_head.mask.v.teeth\n",
    "green_idx = flame_head.inner_mouth_indices\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "permutation = [0, 2, 1]\n",
    "vertices = flame_vertices.detach().cpu().numpy()[:, permutation]  # has shape (n_vertices, 3)\n",
    "faces = flame_head.faces.detach().cpu().numpy()[:, permutation]  # has shape (n_faces, 3)\n",
    "\n",
    "blue_idx = blue_idx.cpu().numpy()\n",
    "blue_points = vertices[blue_idx]\n",
    "green_idx = green_idx.cpu().numpy()\n",
    "green_points = vertices[green_idx]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Mesh3d(\n",
    "        x=vertices[:, 0],\n",
    "        y=vertices[:, 1],\n",
    "        z=vertices[:, 2],\n",
    "        i=faces[:, 0],\n",
    "        j=faces[:, 1],\n",
    "        k=faces[:, 2],\n",
    "        color='lightpink',\n",
    "        opacity=0.50,\n",
    "    ))\n",
    "\n",
    "# # plot points\n",
    "# fig.add_trace(\n",
    "#     go.Scatter3d(\n",
    "#         x=vertices[:, 0],\n",
    "#         y=vertices[:, 1],\n",
    "#         z=vertices[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=2,\n",
    "#             color='red',\n",
    "#         ),\n",
    "#     ))\n",
    "\n",
    "# plot blue points\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=blue_points[:, 0],\n",
    "        y=blue_points[:, 1],\n",
    "        z=blue_points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(color='blue',),\n",
    "    ))\n",
    "\n",
    "# plot green points\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=green_points[:, 0],\n",
    "        y=green_points[:, 1],\n",
    "        z=green_points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(color='green',),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot flame vertices\n",
    "lower = True\n",
    "upper = True\n",
    "show_lips = False\n",
    "connect_rings = False\n",
    "inside_mouth_ring_plot = True\n",
    "\n",
    "vertices = flame_vertices.cpu().numpy()\n",
    "lips = flame_vertices[flame_head.mask.v.lips].cpu().numpy()  # red\n",
    "\n",
    "lips_outside_ring_lower = flame_vertices[  # green\n",
    "    flame_head.mask.v.lip_outside_ring_lower].cpu().detach().numpy()\n",
    "lips_outside_ring_upper = flame_vertices[\n",
    "    flame_head.mask.v.lip_outside_ring_upper].cpu().detach().numpy()\n",
    "outside_ring = []\n",
    "if lower:\n",
    "    outside_ring.append(lips_outside_ring_lower)\n",
    "if upper:\n",
    "    outside_ring.append(lips_outside_ring_upper)\n",
    "outside_ring = np.concatenate(outside_ring, axis=0)\n",
    "\n",
    "lips_inside_ring_lower = flame_vertices[  # black\n",
    "    flame_head.mask.v.lip_inside_ring_lower].cpu().detach().numpy()\n",
    "lips_inside_ring_upper = flame_vertices[\n",
    "    flame_head.mask.v.lip_inside_ring_upper].cpu().detach().numpy()\n",
    "inside_ring = []\n",
    "if lower:\n",
    "    inside_ring.append(lips_inside_ring_lower)\n",
    "if upper:\n",
    "    inside_ring.append(lips_inside_ring_upper)\n",
    "inside_ring = np.concatenate(inside_ring, axis=0)\n",
    "\n",
    "connection_lines = inside_ring - outside_ring\n",
    "\n",
    "inside_mouth_ring = inside_ring + connection_lines\n",
    "connection_lines = inside_mouth_ring - inside_ring\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "if show_lips:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=lips[:, 2],\n",
    "            y=lips[:, 0],\n",
    "            z=lips[:, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red'),\n",
    "            name='Lips'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=outside_ring[:, 2],\n",
    "        y=outside_ring[:, 0],\n",
    "        z=outside_ring[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(color='green'),\n",
    "        name='Outside Ring'))\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=inside_ring[:, 2],\n",
    "        y=inside_ring[:, 0],\n",
    "        z=inside_ring[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(color='black'),\n",
    "        name='Inside Ring'))\n",
    "\n",
    "if connect_rings:\n",
    "    for i in range(connection_lines.shape[0]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[outside_ring[i, 2], inside_ring[i, 2]],\n",
    "                y=[outside_ring[i, 0], inside_ring[i, 0]],\n",
    "                z=[outside_ring[i, 1], inside_ring[i, 1]],\n",
    "                mode='lines',\n",
    "                line=dict(color='blue'),\n",
    "                name='Connection Lines'))\n",
    "\n",
    "if inside_mouth_ring_plot:\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=inside_mouth_ring[:, 2],\n",
    "            y=inside_mouth_ring[:, 0],\n",
    "            z=inside_mouth_ring[:, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red'),\n",
    "            name='Inside Mouth Ring'))\n",
    "\n",
    "fig.update_layout(scene=dict(aspectmode='data'), title='Flame Vertices Plot')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.code_talker.stage1_runner import Stage1Runner\n",
    "\n",
    "ckpt = 'tb_logs/vector_quantization/default_quantization/version_0/checkpoints/epoch=199-step=15400.ckpt'\n",
    "model = Stage1Runner.load_from_checkpoint(ckpt)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model.predict(flame_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "time = 100\n",
    "c_in = 15429\n",
    "x = torch.randn(batch, time, c_in).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model.canonical_flame_vertices.reshape(1, -1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.render_vertex_video import _generate_image\n",
    "\n",
    "img = _generate_image(v, flame_head, time_step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import QuantizationDataset, UnbatchedFlameParams\n",
    "from thesis.constants import TRAIN_SEQUENCES\n",
    "\n",
    "dataset = QuantizationDataset(TRAIN_SEQUENCES, window_size=None)\n",
    "idx = np.random.randint(0, len(dataset))\n",
    "print(f\"idx: {idx}\")\n",
    "flame, _, _ = dataset[idx]\n",
    "flame = UnbatchedFlameParams(*flame)\n",
    "flame.expr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SequenceManager\n",
    "from thesis.flame import FlameHead\n",
    "\n",
    "sm = SequenceManager(3)\n",
    "flame_parmas = sm.flame_params[0:1]\n",
    "flame_head = FlameHead()\n",
    "v = flame_head.forward(flame_parmas)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.code_talker.models.code_talker_config import QuantizerConfig, QuantizationTrainingConfig\n",
    "from thesis.code_talker.stage1_runner import Stage1Runner\n",
    "\n",
    "config = QuantizerConfig()\n",
    "training_config = QuantizationTrainingConfig()\n",
    "runner = Stage1Runner(config, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "time = 101\n",
    "input_dim = config.input_dim\n",
    "x = torch.randn(batch_size, time, input_dim)\n",
    "template = torch.randn(batch_size, input_dim)\n",
    "\n",
    "quant, emb_loss, info = runner.model.encode(x)\n",
    "print(quant.shape)  # (batch_size, z_quant_dim, time * face_qun) # (i.e. B, C, L*F)\n",
    "\n",
    "dec = runner.model.decode(quant)\n",
    "print(dec.shape)  # (batch_size, time, input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.video_utils import side_by_side\n",
    "\n",
    "side_by_side(\n",
    "    # video_gt='tmp/video_gt.mp4',\n",
    "    # output_path='tmp/gt_flame_and_pred.mp4',\n",
    "    video_pred='tmp/video_pred.mp4',\n",
    "    video_gt='tmp/gt/sequence_100.mp4',\n",
    "    output_path='tmp/gt_video_and_pred.mp4',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.render_video import render_gt_video\n",
    "\n",
    "render_gt_video(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_quantization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
