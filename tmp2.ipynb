{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.render_video import render_gt_video\n",
    "\n",
    "render_gt_video(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SequenceManager, UnbatchedFlameParams\n",
    "\n",
    "sm = SequenceManager(3)\n",
    "flame_params = sm.flame_params[:]\n",
    "flame_params = UnbatchedFlameParams(*(a.to('cuda') for a in flame_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.audio_to_flame.windowed import AudioToFlame\n",
    "from thesis.render_video import process_audio, audio_to_flame\n",
    "\n",
    "model_path = 'tb_logs/audio2flame/my_model/version_6/checkpoints/epoch=29-step=10650.ckpt'\n",
    "audio_path = 'tmp/audio_recording_cleaned_s3.ogg'\n",
    "model = AudioToFlame.load_from_checkpoint(model_path)\n",
    "audio_features = process_audio(audio_path)\n",
    "jaw, expr = audio_to_flame(audio_features, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "video = np.load('tmp/video.npy')\n",
    "\n",
    "plt.imshow(video[99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = 'tb_logs/single_frame/2dgs/version_12/checkpoints/epoch=24-step=100000.ckpt'\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management.datasets import MultiSequenceDataset\n",
    "from thesis.constants import TRAIN_CAMS\n",
    "\n",
    "dataset = MultiSequenceDataset(\n",
    "    sequences=[3, 4],\n",
    "    cameras=TRAIN_CAMS,\n",
    "    window_size=9,\n",
    ")\n",
    "a, b, c = dataset[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(9)\n",
    "l = torch.where(a < 2)[0]\n",
    "r = torch.where(a >= 2)[0]\n",
    "l, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management.sequence_manager import SequenceManager\n",
    "\n",
    "sm = SequenceManager(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import MultiSequenceManager\n",
    "from thesis.constants import TRAIN_SEQUENCES\n",
    "\n",
    "msm = MultiSequenceManager(TRAIN_SEQUENCES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm.lengths[7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_quantization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
