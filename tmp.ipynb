{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEQUENCE CODE for per-gaussian movement !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_frames: 124, pred_frames: 122\n"
     ]
    }
   ],
   "source": [
    "from thesis.data_management import SequenceManager\n",
    "\n",
    "sequence = 93\n",
    "sm = SequenceManager(sequence)\n",
    "a = torch.load(\n",
    "    f'/home/schlack/thesis-quantization/saved_vertex_preds/sequence_{sequence}.pt',\n",
    "    weights_only=True)\n",
    "print(f'n_frames: {len(sm)}, pred_frames: {a.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video ablations/ablations_final/with_2dgs/flame/videos/sequence_80_side_by_side.mp4.\n",
      "MoviePy - Writing audio in sequence_80_side_by_sideTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ablations/ablations_final/with_2dgs/flame/videos/sequence_80_side_by_side.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame_index:  99%|█████████▉| 261/263 [00:11<00:00, 22.99it/s, now=None]/home/schlack/miniconda3/envs/thesis_quantization/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_reader.py:157: UserWarning: In file ablations/ablations_final/with_2dgs/flame/videos/sequence_3_gt.mp4, 5293200 bytes wanted but 0 bytes read at frame index 262 (out of a total 263 frames), at time 8.73/8.78 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\n",
      "/home/schlack/miniconda3/envs/thesis_quantization/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_reader.py:157: UserWarning: In file ablations/ablations_final/with_2dgs/flame/videos/sequence_3.mp4, 5293200 bytes wanted but 0 bytes read at frame index 262 (out of a total 263 frames), at time 8.73/8.78 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ablations/ablations_final/with_2dgs/flame/videos/sequence_80_side_by_side.mp4\n"
     ]
    }
   ],
   "source": [
    "from thesis.video_utils import side_by_side\n",
    "\n",
    "side_by_side(\n",
    "    video_gt='ablations/ablations_final/with_2dgs/flame/videos/sequence_3_gt.mp4',\n",
    "    video_pred='ablations/ablations_final/with_2dgs/flame/videos/sequence_3.mp4',\n",
    "    output_path='ablations/ablations_final/with_2dgs/flame/videos/sequence_80_side_by_side.mp4',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 1604, 1100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thesis.evaluation_runner import load_compressed_array\n",
    "\n",
    "path = 'ablations/ablations_final/with_2dgs/flame/sequence_3'\n",
    "reference_path = f'{path}.npy'\n",
    "bz2_path = f'{path}.bz2'\n",
    "gzip_path = f'{path}.gzip'\n",
    "lzma_path = f'{path}.lzma'\n",
    "\n",
    "reference = np.load(reference_path)\n",
    "reference.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5443, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thesis.gaussian_splatting.implicit_sequence_adjustment import ImplicitSequenceAdjustment\n",
    "\n",
    "isa = ImplicitSequenceAdjustment()\n",
    "a = torch.tensor(3)  #.unsqueeze(0).repeat(4)\n",
    "b = torch.tensor(4)  #.unsqueeze(0).repeat(4)\n",
    "isa(a, b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_config() missing 1 required positional argument: 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthesis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[1;32m      4\u001b[0m config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs/single_frame.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<@beartype(thesis.config.load_config) at 0x76468e03beb0>:60\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(__beartype_get_violation, __beartype_conf, __beartype_object_130054634925232, __beartype_object_130054590464176, __beartype_object_93998524704368, __beartype_object_93998316979184, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_config() missing 1 required positional argument: 'mode'"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "from thesis.config import load_config\n",
    "\n",
    "config_path = \"configs/single_frame.yml\"\n",
    "config = load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single frame model\n",
    "from thesis.gaussian_splatting.single_frame import GaussianSplattingSingleFrame\n",
    "\n",
    "model = GaussianSplattingSingleFrame(\n",
    "    gaussian_splatting_settings=config.gaussian_splatting_settings,\n",
    "    learning_rates=config.learning_rates,\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "params = model.splats\n",
    "optimizers, schedulers = model.configure_optimizers()\n",
    "splat_optimizers = {k: optimizers[i] for i, k in enumerate(model.splat_optimizer_keys)}\n",
    "model.strategy.check_sanity(params, splat_optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SingleSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = SingleSequenceDataset(\n",
    "    sequence=config.sequence,\n",
    "    start_idx=config.frame,\n",
    "    end_idx=config.frame + 1,\n",
    "    n_cameras_per_frame=config.gaussian_splatting_settings.camera_batch_size)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))\n",
    "batch = train_set.prepare_data(a)\n",
    "rendered_images, rendered_alphas, infos = model.forward(\n",
    "    intrinsics=batch.intrinsics,\n",
    "    world_2_cam=batch.world_2_cam,\n",
    "    cam_2_world=None,\n",
    "    image_height=int(batch.image.shape[1]),\n",
    "    image_width=int(batch.image.shape[2]),\n",
    "    # color_correction=batch.color_correction, # TODO: fix color correction\n",
    "    cur_sh_degree=None,\n",
    "    se3_transform=batch.se3_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from dreifus.render import project\n",
    "from dreifus.matrix import Pose, Intrinsics\n",
    "\n",
    "intrinsics = Intrinsics(batch.intrinsics[0].detach().cpu().numpy())\n",
    "pose = Pose(batch.world_2_cam[0].detach().cpu().numpy())\n",
    "projected = project(model.splats['means'].detach().cpu().numpy(), pose, intrinsics)\n",
    "image = rendered_images[0].detach().cpu().numpy()\n",
    "projected_x = projected[:, 0].round().astype(int)\n",
    "projected_y = projected[:, 1].round().astype(int)\n",
    "valid_x = (0 <= projected_x) & (projected_x < image.shape[1])\n",
    "valid_y = (0 <= projected_y) & (projected_y < image.shape[0])\n",
    "valid_xy = valid_x & valid_y\n",
    "print(f\"{valid_xy.sum() / projected.shape[0] * 100:.1f}% of the vertices are visible\"\n",
    "      f\" i.e. {valid_xy.sum()} out of {projected.shape[0]}\\n\")\n",
    "for y, x in zip(projected_y[valid_xy], projected_x[valid_xy]):\n",
    "    for i in range(-3, 3):\n",
    "        if not 0 <= y + i < image.shape[0]:\n",
    "            continue\n",
    "        for j in range(-3, 3):\n",
    "            if not 0 <= x + j < image.shape[1]:\n",
    "                continue\n",
    "            image[y + i, x + j] = [255, 255, 255]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/schlack/master-thesis/data/Paul-audio-85/085/sequences/SEN-05-glow_eyes_sweet_girl/annotations/tracking/FLAME2023_v2/tracked_flame_params.npz'\n",
    "data = np.load(path)\n",
    "data['translation'][72 // 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_quantization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
