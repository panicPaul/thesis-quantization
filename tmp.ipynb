{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SequenceManager\n",
    "\n",
    "sm = SequenceManager(3)\n",
    "w2c = sm.cameras[1]\n",
    "c2w = torch.linalg.inv(w2c)\n",
    "cam_pos = c2w[:, :3, 3]\n",
    "center = cam_pos.mean(dim=0)\n",
    "dist_to_center = torch.linalg.norm(cam_pos - center, dim=1)\n",
    "diagonal = torch.max(dist_to_center)\n",
    "diagonal * 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.flame import FlameHeadVanilla\n",
    "from thesis.render_vertex_video import render_vertex_video\n",
    "\n",
    "flame_head = FlameHeadVanilla()\n",
    "faces = flame_head.faces\n",
    "sequence = 86\n",
    "a = torch.load(f'saved_vertex_preds/sequence_{sequence}_flame.pt').cpu()\n",
    "# audio_path = '/home/schlack/CodeTalker/demo/wav/man.wav'\n",
    "audio_path = f'/home/schlack/new_master_thesis/data/nersemble/Paul-audio-856/856/sequences/sequence_{sequence:04d}/audio/audio_recording.ogg'\n",
    "output_path = 'demo.mp4'\n",
    "\n",
    "render_vertex_video(\n",
    "    vertices=a,\n",
    "    faces=faces,\n",
    "    audio_path=audio_path,\n",
    "    output_path=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import evaluate\n",
    "\n",
    "pred_dir = 'tmp/pred/ablations/7_markov_chain_monte_carlo/flame'\n",
    "gt, pred, l = evaluate(\n",
    "    pred_dir=pred_dir,\n",
    "    sequences=list(range(80, 82)),\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(pred.cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(gt.cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.evaluation import evaluate\n",
    "\n",
    "path = 'tmp/pred/ablations/7_markov_chain_monte_carlo/flame'\n",
    "evaluate(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "from thesis.config import load_config\n",
    "\n",
    "config_path = \"configs/single_frame.yml\"\n",
    "config = load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single frame model\n",
    "from thesis.gaussian_splatting.single_frame import GaussianSplattingSingleFrame\n",
    "\n",
    "model = GaussianSplattingSingleFrame(\n",
    "    gaussian_splatting_settings=config.gaussian_splatting_settings,\n",
    "    learning_rates=config.learning_rates,\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "params = model.splats\n",
    "optimizers, schedulers = model.configure_optimizers()\n",
    "splat_optimizers = {k: optimizers[i] for i, k in enumerate(model.splat_optimizer_keys)}\n",
    "model.strategy.check_sanity(params, splat_optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management import SingleSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = SingleSequenceDataset(\n",
    "    sequence=config.sequence,\n",
    "    start_idx=config.frame,\n",
    "    end_idx=config.frame + 1,\n",
    "    n_cameras_per_frame=config.gaussian_splatting_settings.camera_batch_size)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))\n",
    "batch = train_set.prepare_data(a)\n",
    "rendered_images, rendered_alphas, infos = model.forward(\n",
    "    intrinsics=batch.intrinsics,\n",
    "    world_2_cam=batch.world_2_cam,\n",
    "    cam_2_world=None,\n",
    "    image_height=int(batch.image.shape[1]),\n",
    "    image_width=int(batch.image.shape[2]),\n",
    "    # color_correction=batch.color_correction, # TODO: fix color correction\n",
    "    cur_sh_degree=None,\n",
    "    se3_transform=batch.se3_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from dreifus.render import project\n",
    "from dreifus.matrix import Pose, Intrinsics\n",
    "\n",
    "intrinsics = Intrinsics(batch.intrinsics[0].detach().cpu().numpy())\n",
    "pose = Pose(batch.world_2_cam[0].detach().cpu().numpy())\n",
    "projected = project(model.splats['means'].detach().cpu().numpy(), pose, intrinsics)\n",
    "image = rendered_images[0].detach().cpu().numpy()\n",
    "projected_x = projected[:, 0].round().astype(int)\n",
    "projected_y = projected[:, 1].round().astype(int)\n",
    "valid_x = (0 <= projected_x) & (projected_x < image.shape[1])\n",
    "valid_y = (0 <= projected_y) & (projected_y < image.shape[0])\n",
    "valid_xy = valid_x & valid_y\n",
    "print(f\"{valid_xy.sum() / projected.shape[0] * 100:.1f}% of the vertices are visible\"\n",
    "      f\" i.e. {valid_xy.sum()} out of {projected.shape[0]}\\n\")\n",
    "for y, x in zip(projected_y[valid_xy], projected_x[valid_xy]):\n",
    "    for i in range(-3, 3):\n",
    "        if not 0 <= y + i < image.shape[0]:\n",
    "            continue\n",
    "        for j in range(-3, 3):\n",
    "            if not 0 <= x + j < image.shape[1]:\n",
    "                continue\n",
    "            image[y + i, x + j] = [255, 255, 255]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/schlack/master-thesis/data/Paul-audio-85/085/sequences/SEN-05-glow_eyes_sweet_girl/annotations/tracking/FLAME2023_v2/tracked_flame_params.npz'\n",
    "data = np.load(path)\n",
    "data['translation'][72 // 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_quantization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
