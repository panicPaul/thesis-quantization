{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "if 'has_been_executed' not in locals():\n",
    "    print(\"Changing directory to the root of the project\")\n",
    "    os.chdir(\"../../../\")\n",
    "    has_been_executed = True\n",
    "else:\n",
    "    print(\"The directory is correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management.sequence_manager import SequenceManager\n",
    "from matplotlib import pyplot as plt\n",
    "from thesis.constants import SERIALS, TRAIN_CAMS, TEST_CAMS\n",
    "\n",
    "sequence_manager = SequenceManager(3, cameras=list(range(16)))\n",
    "intrinsics, extrinsics, names = sequence_manager.cameras\n",
    "print(f\"Intrinsics shape: {intrinsics.shape}\")\n",
    "print(f\"Extrinsics shape: {extrinsics.shape}\")\n",
    "print(f\"Names: {names}\")\n",
    "color_correction = sequence_manager.color_correction\n",
    "print(f\"Color correction shape: {color_correction.shape}\")\n",
    "audio, sr = sequence_manager.load_audio()\n",
    "print(f\"Audio shape: {audio.shape}\")\n",
    "print(f\"Sample rate: {sr}\")\n",
    "\n",
    "if False:\n",
    "    for i in range(16):\n",
    "        image = sequence_manager.images[100, i]\n",
    "        plt.imshow(image)\n",
    "        title = f\"Camera {i}\"\n",
    "        if i in TRAIN_CAMS:\n",
    "            title += \" (train)\"\n",
    "        elif i in TEST_CAMS:\n",
    "            title += \" (test)\"\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi sequence manager\n",
    "from thesis.data_management.sequence_manager import MultiSequenceManager\n",
    "from thesis.constants import TRAIN_SEQUENCES\n",
    "\n",
    "msm = MultiSequenceManager(TRAIN_SEQUENCES, cameras=list(range(16)))\n",
    "print(f\"Number of frames: {len(msm):,}\")\n",
    "msm[0].images[0, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management.datasets import SingleSequenceDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "ssd = SingleSequenceDataset(sequence=3, n_cameras_per_frame=1)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ssd,\n",
    "    batch_size=None,\n",
    "    num_workers=12,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ssd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.se3_transform.rotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def time_data_loader(data_loader, n_steps=1_000):\n",
    "    iterator = iter(data_loader)\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        try:\n",
    "            data = next(iterator)\n",
    "        except StopIteration:\n",
    "            iterator = iter(data_loader)\n",
    "            data = next(iterator)\n",
    "        data = data_loader.dataset.prepare_data(data)\n",
    "\n",
    "\n",
    "time_data_loader(dataloader, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_management.datasets import QuantizationDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from thesis.constants import TRAIN_SEQUENCES\n",
    "\n",
    "qd = QuantizationDataset(sequences=[3])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    qd,\n",
    "    batch_size=32,\n",
    "    num_workers=10,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "a = qd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data_loader(dataloader, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_quantization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
